{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for handling data and files\n",
        "import pandas as pd             # pandas is a powerful data manipulation and analysis library.\n",
        "import io                       # The io module provides the Python interfaces to stream handling.\n",
        "from io import StringIO         # StringIO is used to handle text data in memory as file objects.\n",
        "import string                   # The string module contains various string constant which are useful.\n",
        "from collections import Counter # Counter is a dict subclass for counting hashable objects.\n",
        "\n",
        "# Attempt to import StringIO from the StringIO module for compatibility with older Python versions.\n",
        "try:\n",
        "    from StringIO import StringIO  # Try importing from StringIO if it's available in the Python version.\n",
        "except ImportError:\n",
        "    from io import StringIO        # If not available, fall back to StringIO from the io module.\n",
        "\n",
        "# Import the files module from google.colab to interact with the file system.\n",
        "from google.colab import files\n",
        "\n",
        "# Prompt for file upload via the Google Colab interface to upload the test dataset and store the uploaded files in a variable.\n",
        "# This is similar to the previous procedure but now focusing on the test dataframe.\n",
        "uploaded_files_secondary = files.upload()  # This method shows a widget to upload files and returns a dictionary\n",
        "                                           # of the files which were uploaded. The dictionary keys are the file names\n",
        "                                           # and values are the data which have been uploaded."
      ],
      "metadata": {
        "id": "yH1jqda_3ywl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "UJa6nZYNiFj9",
        "outputId": "efe0b877-731c-4f24-be11-47b969374075"
      },
      "source": [
        "# Read the uploaded Excel file into a pandas DataFrame\n",
        "# 'header=None' indicates that the first row in the file is not treated as the header row,\n",
        "test_dataframe = pd.read_csv(io.BytesIO(uploaded_files_secondary[\"FileName.csv\"]), header=None)\n",
        "\n",
        "test_dataframe.dropna(inplace=True, axis=1)\n",
        "# Drop all columns that contain only NaN values\n",
        "# 'inplace=True' modifies the existing DataFrame without creating a new one\n",
        "# 'axis=1' specifies that columns should be dropped (not rows)\n",
        "\n",
        "# Display the dataframe\n",
        "test_dataframe\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>neptune</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>neptune</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>neptune</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>neptune</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>neptune</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22539</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>smtp</td>\n",
              "      <td>SF</td>\n",
              "      <td>794</td>\n",
              "      <td>333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>100</td>\n",
              "      <td>141</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22540</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>317</td>\n",
              "      <td>938</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.18</td>\n",
              "      <td>197</td>\n",
              "      <td>255</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22541</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>54540</td>\n",
              "      <td>8314</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>back</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22542</th>\n",
              "      <td>0</td>\n",
              "      <td>udp</td>\n",
              "      <td>domain_u</td>\n",
              "      <td>SF</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>255</td>\n",
              "      <td>252</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22543</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>sunrpc</td>\n",
              "      <td>REJ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>255</td>\n",
              "      <td>21</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1.00</td>\n",
              "      <td>mscan</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22544 rows Ã— 43 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       1    2         3    4      5     6   ...    38   39    40    41       42  43\n",
              "0       0  tcp      http   S0      0     0  ...  0.00  0.0  0.00  0.00  neptune  21\n",
              "1       0  tcp      http   S0      0     0  ...  1.00  1.0  0.00  0.00  neptune  21\n",
              "2       0  tcp      http   S0      0     0  ...  1.00  1.0  0.00  0.00  neptune  21\n",
              "3       0  tcp      http   S0      0     0  ...  1.00  1.0  0.00  0.00  neptune  21\n",
              "4       0  tcp      http   S0      0     0  ...  1.00  1.0  0.00  0.00  neptune  21\n",
              "...    ..  ...       ...  ...    ...   ...  ...   ...  ...   ...   ...      ...  ..\n",
              "22539   0  tcp      smtp   SF    794   333  ...  0.01  0.0  0.00  0.00   normal  21\n",
              "22540   0  tcp      http   SF    317   938  ...  0.01  0.0  0.00  0.00   normal  21\n",
              "22541   0  tcp      http   SF  54540  8314  ...  0.00  0.0  0.07  0.07     back  15\n",
              "22542   0  udp  domain_u   SF     42    42  ...  0.00  0.0  0.00  0.00   normal  21\n",
              "22543   0  tcp    sunrpc  REJ      0     0  ...  0.00  0.0  0.44  1.00    mscan  14\n",
              "\n",
              "[22544 rows x 43 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtfWCoqjjcMK"
      },
      "source": [
        "# Create column array for the dataframe, based on the given file\n",
        "test_dataframe.columns = [\n",
        "    'duration',\n",
        "    'protocol_type',\n",
        "    'service',\n",
        "    'flag',\n",
        "    'src_bytes',\n",
        "    'dst_bytes',\n",
        "    'land',\n",
        "    'wrong_fragment',\n",
        "    'urgent',\n",
        "    'hot',\n",
        "    'num_failed_logins',\n",
        "    'logged_in',\n",
        "    'num_compromised',\n",
        "    'root_shell',\n",
        "    'su_attempted',\n",
        "    'num_root',\n",
        "    'num_file_creations',\n",
        "    'num_shells',\n",
        "    'num_access_files',\n",
        "    'num_outbound_cmds',\n",
        "    'is_host_login',\n",
        "    'is_guest_login',\n",
        "    'count',\n",
        "    'srv_count',\n",
        "    'serror_rate',\n",
        "    'srv_serror_rate',\n",
        "    'rerror_rate',\n",
        "    'srv_rerror_rate',\n",
        "    'same_srv_rate',\n",
        "    'diff_srv_rate',\n",
        "    'srv_diff_host_rate',\n",
        "    'dst_host_count',\n",
        "    'dst_host_srv_count',\n",
        "    'dst_host_same_srv_rate',\n",
        "    'dst_host_diff_srv_rate',\n",
        "    'dst_host_same_src_port_rate',\n",
        "    'dst_host_srv_diff_host_rate',\n",
        "    'dst_host_serror_rate',\n",
        "    'dst_host_srv_serror_rate',\n",
        "    'dst_host_rerror_rate',\n",
        "    'dst_host_srv_rerror_rate',\n",
        "    'outcome',\n",
        "    'new'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4kgsOHLpE65"
      },
      "source": [
        "# Define a function to apply z-score normalization to numeric columns in the dataframe\n",
        "# Mainly done to improve the performance of our algorithm by speeding up learning and convergence.\n",
        "def encode_numeric_zscore(dataframe, column_name, mean=None, standard_deviation=None):\n",
        "    \"\"\"\n",
        "    Normalizes a numeric column in the dataframe using z-score standardization.\n",
        "\n",
        "    Parameters:\n",
        "    - dataframe (pd.DataFrame): The dataframe containing the column to normalize.\n",
        "    - column_name (str): The name of the column to normalize.\n",
        "    - mean (float, optional): Precomputed mean value. If None, the mean is calculated from the column.\n",
        "    - standard_deviation (float, optional): Precomputed standard deviation. If None, it's calculated from the column.\n",
        "    \"\"\"\n",
        "    # Calculate mean if not provided\n",
        "    if mean is None:\n",
        "        mean = dataframe[column_name].mean()\n",
        "\n",
        "    # Calculate standard deviation if not provided\n",
        "    if standard_deviation is None:\n",
        "        standard_deviation = dataframe[column_name].std()\n",
        "\n",
        "    # Apply z-score normalization\n",
        "    dataframe[column_name] = (dataframe[column_name] - mean) / standard_deviation\n",
        "\n",
        "# Define a function to convert categorical text columns into dummy/one-hot encoded variables and drop the original column\n",
        "def encode_text_dummy(dataframe, column_name):\n",
        "    \"\"\"\n",
        "    Encodes a categorical text column into dummy variables and removes the original column.\n",
        "\n",
        "    Parameters:\n",
        "    - dataframe (pd.DataFrame): The dataframe containing the categorical column.\n",
        "    - column_name (str): The name of the categorical column to encode.\n",
        "    \"\"\"\n",
        "    # Generate dummy variables for the specified categorical column\n",
        "    dummies = pd.get_dummies(dataframe[column_name])\n",
        "\n",
        "    # Iterate through each category in the dummy variables\n",
        "    for category in dummies.columns:\n",
        "        # Create a new column name by combining the original column name with the category\n",
        "        dummy_column_name = str(column_name) + \"-\" + str(category)\n",
        "\n",
        "        # Add the dummy variable to the dataframe\n",
        "        dataframe[dummy_column_name] = dummies[category]\n",
        "\n",
        "    # Remove the original categorical column from the dataframe\n",
        "    dataframe.drop(column_name, axis=1, inplace=True)\n",
        "\n",
        "# Encoding numeric features for test data\n",
        "\n",
        "\n",
        "# Apply z-score normalization to various numeric columns in the training dataframe\n",
        "encode_numeric_zscore(test_dataframe, 'duration')\n",
        "encode_numeric_zscore(test_dataframe, 'src_bytes')\n",
        "encode_numeric_zscore(test_dataframe, 'dst_bytes')\n",
        "encode_numeric_zscore(test_dataframe, 'land')\n",
        "encode_numeric_zscore(test_dataframe, 'wrong_fragment')\n",
        "encode_numeric_zscore(test_dataframe, 'urgent')\n",
        "encode_numeric_zscore(test_dataframe, 'hot')\n",
        "encode_numeric_zscore(test_dataframe, 'num_failed_logins')\n",
        "encode_numeric_zscore(test_dataframe, 'logged_in')\n",
        "encode_numeric_zscore(test_dataframe, 'num_compromised')\n",
        "encode_numeric_zscore(test_dataframe, 'root_shell')\n",
        "encode_numeric_zscore(test_dataframe, 'su_attempted')\n",
        "encode_numeric_zscore(test_dataframe, 'num_root')\n",
        "encode_numeric_zscore(test_dataframe, 'num_file_creations')\n",
        "encode_numeric_zscore(test_dataframe, 'num_shells')\n",
        "encode_numeric_zscore(test_dataframe, 'num_access_files')\n",
        "encode_numeric_zscore(test_dataframe, 'num_outbound_cmds')\n",
        "encode_numeric_zscore(test_dataframe, 'is_host_login')\n",
        "encode_numeric_zscore(test_dataframe, 'is_guest_login')\n",
        "encode_numeric_zscore(test_dataframe, 'count')\n",
        "encode_numeric_zscore(test_dataframe, 'srv_count')\n",
        "encode_numeric_zscore(test_dataframe, 'serror_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'srv_serror_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'rerror_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'srv_rerror_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'same_srv_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'diff_srv_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'srv_diff_host_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'dst_host_count')\n",
        "encode_numeric_zscore(test_dataframe, 'dst_host_srv_count')\n",
        "encode_numeric_zscore(test_dataframe, 'dst_host_same_srv_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'dst_host_diff_srv_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'dst_host_same_src_port_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'dst_host_srv_diff_host_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'dst_host_serror_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'dst_host_srv_serror_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'dst_host_rerror_rate')\n",
        "encode_numeric_zscore(test_dataframe, 'dst_host_srv_rerror_rate')\n",
        "\n",
        "# After encoding all numeric features, remove any remaining columns with NaN values from the test_dataframe\n",
        "test_dataframe.dropna(inplace=True, axis=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f45vuaoy1GsL",
        "outputId": "c7153398-796c-43dd-c0cf-ad207811f998"
      },
      "source": [
        "# Encoding categorical features for test data\n",
        "\n",
        "# Generate dummy variables for the each categorical column that had strings in it, in order to make processing of the columns possible\n",
        "\n",
        "protocol_dummies = pd.get_dummies(test_dataframe['protocol_type'])\n",
        "service_dummies = pd.get_dummies(test_dataframe['service'])\n",
        "flag_dummies = pd.get_dummies(test_dataframe['flag'])\n",
        "\n",
        "# Concatenate the newly created dummy variables to the test_dataframe along the columns axis\n",
        "\n",
        "test_dataframe = pd.concat((test_dataframe, protocol_dummies, service_dummies, flag_dummies), axis=1)\n",
        "\n",
        "# Remove the string column labelings\n",
        "test_dataframe.pop('protocol_type')\n",
        "test_dataframe.pop('service')\n",
        "test_dataframe.pop('flag')\n",
        "\n",
        "# Display the test_dataframe to verify that the categorical columns have been successfully encoded and removed\n",
        "# This helps in confirming that the dataframe is now ready for model evaluation without redundant columns\n",
        "\n",
        "test_dataframe\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         S0\n",
              "1         S0\n",
              "2         S0\n",
              "3         S0\n",
              "4         S0\n",
              "        ... \n",
              "22539     SF\n",
              "22540     SF\n",
              "22541     SF\n",
              "22542     SF\n",
              "22543    REJ\n",
              "Name: flag, Length: 22544, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgOKQR7D_DAT"
      },
      "source": [
        "# Import the NumPy library for numerical operations\n",
        "import numpy as np\n",
        "\n",
        "# Extract all feature values from the test_dataframe as a NumPy array\n",
        "# This includes all columns in the dataframe\n",
        "test_features = test_dataframe.values\n",
        "\n",
        "# Extract the 'outcome' column from test_dataframe as the target labels\n",
        "# This separates the target variable from the feature set\n",
        "# Done mainly so that our machine won't see the answer prematurely\n",
        "test_labels = test_dataframe['outcome'].values\n",
        "\n",
        "# Remove the column at index 37 from the test_features array\n",
        "# Assuming that the 'outcome' column is at index 37, this step excludes it from the features\n",
        "test_features = np.delete(test_features, 37, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0FS-CoejCRo"
      },
      "source": [
        "# Import necessary libraries for model training and timing\n",
        "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
        "from sklearn import tree                            # For Decision Tree classifier\n",
        "import time                                        # For measuring execution time\n",
        "\n",
        "\n",
        "def intelect(features, labels, test_size_ratio):\n",
        "    \"\"\"\n",
        "    Trains a Decision Tree classifier on the provided features and labels,\n",
        "    evaluates its accuracy, and records the time taken for fitting and prediction.\n",
        "\n",
        "    Parameters:\n",
        "    - features (np.ndarray): The feature matrix for the dataset.\n",
        "    - labels (np.ndarray): The target labels for the dataset.\n",
        "    - test_size_ratio (float): The proportion of the dataset to include in the test split.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize an empty string to store the fitting message, readable and formatted message\n",
        "    fitting_message = ''\n",
        "\n",
        "    # Record the start time for the fitting process\n",
        "    start_time_fitting = time.perf_counter()\n",
        "\n",
        "    # Split the dataset into training and testing sets based on the specified test size ratio\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        features, labels, test_size=test_size_ratio, random_state=0\n",
        "    )\n",
        "\n",
        "    # Initialize the Decision Tree classifier with a maximum depth of 1000\n",
        "    decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "\n",
        "    # Train the classifier on the training data\n",
        "    decision_tree_classifier.fit(x_train, y_train)\n",
        "\n",
        "    # Record the finish time for the fitting process\n",
        "    finish_time_fitting = time.perf_counter()\n",
        "\n",
        "    # Create a list of details about the fitting process\n",
        "    fitting_details = [\n",
        "        'Fitting with ',\n",
        "        test_size_ratio,\n",
        "        ' amount of training data was Finished in ',\n",
        "        round(finish_time_fitting - start_time_fitting, 2),\n",
        "        ' second(s)'\n",
        "    ]\n",
        "\n",
        "    # Record the start time for the prediction process\n",
        "    start_time_prediction = time.perf_counter()\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = decision_tree_classifier.predict(x_test)\n",
        "\n",
        "    # Calculate the accuracy of the classifier on the test data\n",
        "    accuracy = decision_tree_classifier.score(x_test, y_test)\n",
        "\n",
        "    # Print the accuracy of the model\n",
        "    print('Accuracy of ', test_size_ratio, ' amount of training data ', accuracy)\n",
        "\n",
        "    # Record the finish time for the prediction process\n",
        "    finish_time_prediction = time.perf_counter()\n",
        "\n",
        "    # Create a list of details about the prediction process\n",
        "    prediction_details = [\n",
        "        'Predicting and calculating accuracy of ',\n",
        "        str(test_size_ratio),\n",
        "        ' amount of training data was Finished in ',\n",
        "        round(finish_time_prediction - start_time_prediction, 2),\n",
        "        ' second(s)'\n",
        "    ]\n",
        "\n",
        "    # Combine the fitting details into a single formatted string\n",
        "    fitting_message = '. '.join([' '.join(map(str, fitting_details))]) + '.'\n",
        "\n",
        "    # Combine the prediction details into a single formatted string\n",
        "    prediction_message = '. '.join([' '.join(map(str, prediction_details))]) + '.'\n",
        "\n",
        "    # Print the fitting and prediction messages\n",
        "    print(fitting_message)\n",
        "    print(prediction_message)\n",
        "\n",
        "    # Print a separator for clarity in the output\n",
        "    print('-----------------------------------')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rplG2qNfsrdr",
        "outputId": "5121f84f-61ef-4727-b06b-1a1f911c1307"
      },
      "source": [
        "# Import necessary modules for threading and timing\n",
        "import threading  # To create and manage multiple threads\n",
        "\n",
        "\n",
        "# Record the start time of the session to measure total execution time\n",
        "session_start_time = time.perf_counter()\n",
        "\n",
        "\n",
        "# Creating and Starting Threads for Different Test Size Ratios\n",
        "\n",
        "# Threading allows multiple instances of the `intelect` function to run concurrently.\n",
        "# This is beneficial for speeding up the evaluation process when dealing with multiple test sizes.\n",
        "\n",
        "# Create and start a thread for test_size_ratio = 0.1\n",
        "thread_010 = threading.Thread(target=intelect, args=[test_features,test_labels,0.1]) # Pass features, labels, and test size ratio as arguments\n",
        "\n",
        "thread_010.start()                     # Start the thread\n",
        "\n",
        "# Create and start a thread for test_size_ratio = 0.2\n",
        "thread_020 = threading.Thread(target=intelect, args=[test_features,test_labels,0.2]) # Pass features, labels, and test size ratio as arguments\n",
        "\n",
        "thread_020.start()                     # Start the thread\n",
        "\n",
        "# Create and start a thread for test_size_ratio = 0.3\n",
        "thread_030 = threading.Thread(target=intelect, args=[test_features,test_labels,0.3]) # Pass features, labels, and test size ratio as arguments\n",
        "\n",
        "thread_030.start()                     # Start the thread\n",
        "\n",
        "# Create and start a thread for test_size_ratio = 0.5\n",
        "thread_050 = threading.Thread(target=intelect, args=[test_features,test_labels,0.5]) # Pass features, labels, and test size ratio as arguments\n",
        "\n",
        "thread_050.start()                     # Start the thread\n",
        "\n",
        "# Create and start a thread for test_size_ratio = 0.6\n",
        "thread_060 = threading.Thread(target=intelect, args=[test_features,test_labels,0.6]) # Pass features, labels, and test size ratio as arguments\n",
        "\n",
        "thread_060.start()                     # Start the thread\n",
        "\n",
        "# Create and start a thread for test_size_ratio = 0.7\n",
        "thread_070 = threading.Thread(target=intelect, args=[test_features,test_labels,0.7]) # Pass features, labels, and test size ratio as arguments\n",
        "\n",
        "thread_070.start()                     # Start the thread\n",
        "\n",
        "# Create and start a thread for test_size_ratio = 0.8\n",
        "thread_080 = threading.Thread(target=intelect, args=[test_features,test_labels,0.8]) # Pass features, labels, and test size ratio as arguments\n",
        "\n",
        "thread_080.start()                     # Start the thread\n",
        "\n",
        "# Create and start a thread for test_size_ratio = 0.9\n",
        "thread_090 = threading.Thread(target=intelect, args=[test_features,test_labels,0.9]) # Pass features, labels, and test size ratio as arguments\n",
        "\n",
        "thread_090.start()                     # Start the thread\n",
        "\n",
        "# Create and start a thread for test_size_ratio = 0.95\n",
        "thread_095 = threading.Thread(target=intelect, args=[test_features,test_labels,0.95]) # Pass features, labels, and test size ratio as arguments\n",
        "\n",
        "thread_095.start()                     # Start the thread\n",
        "\n",
        "# Create and start a thread for test_size_ratio = 0.99\n",
        "thread_099 = threading.Thread(target=intelect, args=[test_features,test_labels,0.99]) # Pass features, labels, and test size ratio as arguments\n",
        "\n",
        "thread_099.start()                     # Start the thread\n",
        "\n",
        "# Waiting for All Threads to Complete\n",
        "\n",
        "# Threading allows each `intelect` function to run independently for different test_size_ratios.\n",
        "# This concurrent execution can significantly reduce the total time taken compared to sequential execution.\n",
        "\n",
        "# Wait for all threads to complete their execution\n",
        "result_a = thread_010.join()  # Wait for thread_010 (test_size_ratio=0.1) to finish\n",
        "result_b = thread_020.join()  # Wait for thread_020 (test_size_ratio=0.2) to finish\n",
        "result_c = thread_030.join()  # Wait for thread_030 (test_size_ratio=0.3) to finish\n",
        "result_d = thread_050.join()  # Wait for thread_050 (test_size_ratio=0.5) to finish\n",
        "result_e = thread_060.join()  # Wait for thread_060 (test_size_ratio=0.6) to finish\n",
        "result_f = thread_070.join()  # Wait for thread_070 (test_size_ratio=0.7) to finish\n",
        "result_g = thread_080.join()  # Wait for thread_080 (test_size_ratio=0.8) to finish\n",
        "result_h = thread_090.join()  # Wait for thread_090 (test_size_ratio=0.9) to finish\n",
        "result_i = thread_095.join()  # Wait for thread_095 (test_size_ratio=0.95) to finish\n",
        "result_j = thread_099.join()  # Wait for thread_099 (test_size_ratio=0.99) to finish\n",
        "\n",
        "# Finalizing and Reporting\n",
        "\n",
        "# Record the finish time of the session to calculate total execution time\n",
        "final_finish_time = time.perf_counter()\n",
        "\n",
        "# Print the total time taken for the entire session\n",
        "print('Finished in', round(final_finish_time - session_start_time, 2), 'second(s)')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9889135254988913\n",
            "0.9463043376756782\n",
            "0.8783995698732022\n",
            "0.9891328454202706\n",
            "0.9863378282469837\n",
            "0.9753825681969395\n",
            "0.982257706808605\n",
            "0.9889118864577173\n",
            "0.9703302119270577\n",
            "0.9787719409416387\n",
            "Finished in 305.64 second(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcVV05DNDSpK"
      },
      "source": [
        "# Initialize an empty list to store performance data and record the start time\n",
        "# This setup helps in tracking the performance of the algorithm we end up choosing efficiently\n",
        "performance_data = []\n",
        "sd_start_time = time.perf_counter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9dPuJj04wVG",
        "outputId": "d99e19fc-ea72-4cf2-8ef6-3ef22f8f6991"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import ensemble\n",
        "\n",
        "# Start the timer to measure how long it takes to train the Random Forest classifier\n",
        "start = time.perf_counter()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# Here, 10% of the data is used for testing and 90% for training\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.1, random_state=0)\n",
        "\n",
        "# Initialize the Random Forest classifier with 250 trees\n",
        "# More trees typically improve the model's performance but increase computational load\n",
        "random_forest_classifier = ensemble.RandomForestClassifier(n_estimators=250)\n",
        "\n",
        "# Train the Random Forest classifier with the training data\n",
        "random_forest_classifier.fit(x_train, y_train)\n",
        "\n",
        "# Stop the timer after training and calculate the duration\n",
        "finish = time.perf_counter()\n",
        "learning_time_rf = round(finish - start, 2)  # Round the training time to two decimal places\n",
        "\n",
        "# Start the timer again to measure the time taken for making predictions and evaluating the model\n",
        "start = time.perf_counter()\n",
        "\n",
        "# Predict the outcomes for the test dataset\n",
        "predictions_rf = random_forest_classifier.predict(x_test)\n",
        "\n",
        "# Calculate the accuracy of the predictions\n",
        "accuracy_rf = random_forest_classifier.score(x_test, y_test)\n",
        "\n",
        "# Stop the timer after predictions and calculate the duration for prediction\n",
        "finish = time.perf_counter()\n",
        "prediction_time_rf = round(finish - start, 2)  # Round the prediction time to two decimal places\n",
        "\n",
        "# Append the test size, learning time, prediction time, and accuracy to the performance data list\n",
        "# This data is used for further analysis or comparison with other models\n",
        "performance_data.append([0.9, 0.1, learning_time_rf, prediction_time_rf, accuracy_rf])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9870786516853932"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32JM9-ha5IRC"
      },
      "source": [
        "# Measure the start time of the decision tree training session\n",
        "start = time.perf_counter()\n",
        "\n",
        "# Import the necessary modules for the decision tree classifier and data splitting\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets with a test size of 10%\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.1, random_state=0)\n",
        "\n",
        "# Initialize the decision tree classifier with a specified maximum depth of 1000\n",
        "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "\n",
        "# Train the decision tree classifier using the training data\n",
        "decision_tree_classifier.fit(x_train, y_train)\n",
        "\n",
        "# Measure the end time of the training session and calculate the duration\n",
        "finish = time.perf_counter()\n",
        "learning_time_dt = round(finish - start, 2)  # Round the training duration to two decimal places\n",
        "\n",
        "# Measure the start time for predictions\n",
        "start = time.perf_counter()\n",
        "\n",
        "# Make predictions with the decision tree classifier on the testing set\n",
        "y_pred_dt = decision_tree_classifier.predict(x_test)\n",
        "\n",
        "# Calculate the accuracy of the classifier on the testing set\n",
        "accuracy_dt = decision_tree_classifier.score(x_test, y_test)\n",
        "\n",
        "# Measure the end time for predictions and calculate the duration\n",
        "finish = time.perf_counter()\n",
        "prediction_time_dt = round(finish - start, 2)  # Round the prediction duration to two decimal places\n",
        "\n",
        "# Append the test size, learning time, prediction time, and accuracy to the performance data list\n",
        "performance_data.append([0.9, 0.1, learning_time_dt, prediction_time_dt, accuracy_dt])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fItBomOd4zWn"
      },
      "source": [
        "# We repeat all the same steps, only changing the distribution between test and train data sizes\n",
        "start = time.perf_counter()\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.2, random_state=0)\n",
        "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "decision_tree_classifier.fit(x_train, y_train)\n",
        "finish = time.perf_counter()\n",
        "learning_time_dt = round(finish - start, 2)\n",
        "\n",
        "start = time.perf_counter()\n",
        "y_pred_dt = decision_tree_classifier.predict(x_test)\n",
        "accuracy_dt = decision_tree_classifier.score(x_test, y_test)\n",
        "finish = time.perf_counter()\n",
        "prediction_time_dt = round(finish - start, 2)\n",
        "performance_data.append([0.8, 0.2, learning_time_dt, prediction_time_dt, accuracy_dt])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AomX6R7E42Tn"
      },
      "source": [
        "# We repeat all the same steps, only changing the distribution between test and train data sizes\n",
        "start = time.perf_counter()\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.3, random_state=0)\n",
        "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "decision_tree_classifier.fit(x_train, y_train)\n",
        "finish = time.perf_counter()\n",
        "learning_time_dt = round(finish - start, 2)\n",
        "\n",
        "start = time.perf_counter()\n",
        "y_pred_dt = decision_tree_classifier.predict(x_test)\n",
        "accuracy_dt = decision_tree_classifier.score(x_test, y_test)\n",
        "finish = time.perf_counter()\n",
        "prediction_time_dt = round(finish - start, 2)\n",
        "performance_data.append([0.7, 0.3, learning_time_dt, prediction_time_dt, accuracy_dt])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBMbRovK45Mr"
      },
      "source": [
        "# We repeat all the same steps, only changing the distribution between test and train data sizes\n",
        "start = time.perf_counter()\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.4, random_state=0)\n",
        "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "decision_tree_classifier.fit(x_train, y_train)\n",
        "finish = time.perf_counter()\n",
        "learning_time_dt = round(finish - start, 2)\n",
        "\n",
        "start = time.perf_counter()\n",
        "y_pred_dt = decision_tree_classifier.predict(x_test)\n",
        "accuracy_dt = decision_tree_classifier.score(x_test, y_test)\n",
        "finish = time.perf_counter()\n",
        "prediction_time_dt = round(finish - start, 2)\n",
        "performance_data.append([0.6, 0.4, learning_time_dt, prediction_time_dt, accuracy_dt])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YLc2MRn45yi"
      },
      "source": [
        "# We repeat all the same steps, only changing the distribution between test and train data sizes\n",
        "start = time.perf_counter()\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.5, random_state=0)\n",
        "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "decision_tree_classifier.fit(x_train, y_train)\n",
        "finish = time.perf_counter()\n",
        "learning_time_dt = round(finish - start, 2)\n",
        "\n",
        "start = time.perf_counter()\n",
        "y_pred_dt = decision_tree_classifier.predict(x_test)\n",
        "accuracy_dt = decision_tree_classifier.score(x_test, y_test)\n",
        "finish = time.perf_counter()\n",
        "prediction_time_dt = round(finish - start, 2)\n",
        "performance_data.append([0.5, 0.5, learning_time_dt, prediction_time_dt, accuracy_dt])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsB-ho2T46Ri"
      },
      "source": [
        "# We repeat all the same steps, only changing the distribution between test and train data sizes\n",
        "start = time.perf_counter()\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.6, random_state=0)\n",
        "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "decision_tree_classifier.fit(x_train, y_train)\n",
        "finish = time.perf_counter()\n",
        "learning_time_dt = round(finish - start, 2)\n",
        "\n",
        "start = time.perf_counter()\n",
        "y_pred_dt = decision_tree_classifier.predict(x_test)\n",
        "accuracy_dt = decision_tree_classifier.score(x_test, y_test)\n",
        "finish = time.perf_counter()\n",
        "prediction_time_dt = round(finish - start, 2)\n",
        "performance_data.append([0.4, 0.6, learning_time_dt, prediction_time_dt, accuracy_dt])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rb1nklq5HCS"
      },
      "source": [
        "# We repeat all the same steps, only changing the distribution between test and train data sizes\n",
        "start = time.perf_counter()\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.7, random_state=0)\n",
        "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "decision_tree_classifier.fit(x_train, y_train)\n",
        "finish = time.perf_counter()\n",
        "learning_time_dt = round(finish - start, 2)\n",
        "\n",
        "start = time.perf_counter()\n",
        "y_pred_dt = decision_tree_classifier.predict(x_test)\n",
        "accuracy_dt = decision_tree_classifier.score(x_test, y_test)\n",
        "finish = time.perf_counter()\n",
        "prediction_time_dt = round(finish - start, 2)\n",
        "performance_data.append([0.3, 0.7, learning_time_dt, prediction_time_dt, accuracy_dt])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au4Cj2Ds5Hbl"
      },
      "source": [
        "# We repeat all the same steps, only changing the distribution between test and train data sizes\n",
        "start = time.perf_counter()\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.8, random_state=0)\n",
        "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "decision_tree_classifier.fit(x_train, y_train)\n",
        "finish = time.perf_counter()\n",
        "learning_time_dt = round(finish - start, 2)\n",
        "\n",
        "start = time.perf_counter()\n",
        "y_pred_dt = decision_tree_classifier.predict(x_test)\n",
        "accuracy_dt = decision_tree_classifier.score(x_test, y_test)\n",
        "finish = time.perf_counter()\n",
        "prediction_time_dt = round(finish - start, 2)\n",
        "performance_data.append([0.2, 0.8, learning_time_dt, prediction_time_dt, accuracy_dt])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0JS4-Gn5JV3"
      },
      "source": [
        "# We repeat all the same steps, only changing the distribution between test and train data sizes\n",
        "start = time.perf_counter()\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.9, random_state=0)\n",
        "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "decision_tree_classifier.fit(x_train, y_train)\n",
        "finish = time.perf_counter()\n",
        "learning_time_dt = round(finish - start, 2)\n",
        "\n",
        "start = time.perf_counter()\n",
        "y_pred_dt = decision_tree_classifier.predict(x_test)\n",
        "accuracy_dt = decision_tree_classifier.score(x_test, y_test)\n",
        "finish = time.perf_counter()\n",
        "prediction_time_dt = round(finish - start, 2)\n",
        "performance_data.append([0.1, 0.9, learning_time_dt, prediction_time_dt, accuracy_dt])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5rVJos65Kog"
      },
      "source": [
        "start = time.perf_counter()\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.95, random_state=0)\n",
        "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "decision_tree_classifier.fit(x_train, y_train)\n",
        "finish = time.perf_counter()\n",
        "learning_time_dt = round(finish - start, 2)\n",
        "\n",
        "start = time.perf_counter()\n",
        "y_pred_dt = decision_tree_classifier.predict(x_test)\n",
        "accuracy_dt = decision_tree_classifier.score(x_test, y_test)\n",
        "finish = time.perf_counter()\n",
        "prediction_time_dt = round(finish - start, 2)\n",
        "performance_data.append([0.05, 0.95, learning_time_dt, prediction_time_dt, accuracy_dt])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CL9H7PPy07I"
      },
      "source": [
        "# We repeat all the same steps, only changing the distribution between test and train data sizes\n",
        "start = time.perf_counter()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(test_features, test_labels, test_size=0.99, random_state=0)\n",
        "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=1000)\n",
        "decision_tree_classifier.fit(x_train, y_train)\n",
        "finish = time.perf_counter()\n",
        "learning_time_dt = round(finish - start, 2)\n",
        "\n",
        "start = time.perf_counter()\n",
        "y_pred_dt = decision_tree_classifier.predict(x_test)\n",
        "accuracy_dt = decision_tree_classifier.score(x_test, y_test)\n",
        "finish = time.perf_counter()\n",
        "prediction_time_dt = round(finish - start, 2)\n",
        "performance_data.append([0.01, 0.99, learning_time_dt, prediction_time_dt, accuracy_dt])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "7-_bHvjo5z-4",
        "outputId": "d6d83fdd-c480-4e8f-ad36-ab58779ef97a"
      },
      "source": [
        "# Record the start time of the entire modeling session for performance tracking\n",
        "start_full_session = time.perf_counter()\n",
        "\n",
        "# Calculate and print the total duration of the session by subtracting the start time from the current time\n",
        "print('Full session finished in', round(start_full_session - session_start_time, 2), 'second(s)')\n",
        "\n",
        "# Import the pandas library, necessary for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from the performance data collected during the session\n",
        "# This DataFrame organizes the data into specified columns for easier analysis and visualization\n",
        "performance_dataframe = pd.DataFrame(performance_data, columns=[\n",
        "    'train data size',  # Percentage of data used for training\n",
        "    'test data size',   # Percentage of data used for testing\n",
        "    'time for learning dataset seconds',  # Time taken to train the model\n",
        "    'time for predicting and calculating seconds',  # Time taken to make predictions and calculate metrics\n",
        "    'accuracy'  # Accuracy of the model on the test data\n",
        "])\n",
        "\n",
        "# Display the created DataFrame to review the performance metrics of the models\n",
        "performance_dataframe\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full session finished in 1870.54 second(s)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train data size</th>\n",
              "      <th>test data size</th>\n",
              "      <th>time for learning dataset</th>\n",
              "      <th>time for predicting and calculating</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.900</td>\n",
              "      <td>0.10</td>\n",
              "      <td>434.49</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.987640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.800</td>\n",
              "      <td>0.20</td>\n",
              "      <td>216.34</td>\n",
              "      <td>6.27</td>\n",
              "      <td>0.986984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.700</td>\n",
              "      <td>0.30</td>\n",
              "      <td>193.83</td>\n",
              "      <td>9.59</td>\n",
              "      <td>0.983707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.600</td>\n",
              "      <td>0.40</td>\n",
              "      <td>168.52</td>\n",
              "      <td>11.52</td>\n",
              "      <td>0.982442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>144.25</td>\n",
              "      <td>14.34</td>\n",
              "      <td>0.980148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.400</td>\n",
              "      <td>0.60</td>\n",
              "      <td>121.83</td>\n",
              "      <td>16.49</td>\n",
              "      <td>0.978150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.300</td>\n",
              "      <td>0.70</td>\n",
              "      <td>140.72</td>\n",
              "      <td>20.23</td>\n",
              "      <td>0.976001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.200</td>\n",
              "      <td>0.80</td>\n",
              "      <td>96.22</td>\n",
              "      <td>20.61</td>\n",
              "      <td>0.971416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.90</td>\n",
              "      <td>67.71</td>\n",
              "      <td>23.63</td>\n",
              "      <td>0.963210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.005</td>\n",
              "      <td>0.95</td>\n",
              "      <td>60.52</td>\n",
              "      <td>24.04</td>\n",
              "      <td>0.947818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.010</td>\n",
              "      <td>0.99</td>\n",
              "      <td>53.69</td>\n",
              "      <td>22.25</td>\n",
              "      <td>0.882751</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    train data size  ...    accuracy\n",
              "0             0.900  ...    0.987640\n",
              "1             0.800  ...    0.986984\n",
              "2             0.700  ...    0.983707\n",
              "3             0.600  ...    0.982442\n",
              "4             0.500  ...    0.980148\n",
              "5             0.400  ...    0.978150\n",
              "6             0.300  ...    0.976001\n",
              "7             0.200  ...    0.971416\n",
              "8             0.100  ...    0.963210\n",
              "9             0.005  ...    0.947818\n",
              "10            0.010  ...    0.882751\n",
              "\n",
              "[11 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}